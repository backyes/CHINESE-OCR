{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概述\n",
    "\n",
    "本notebook主要介绍如何进行中文OCR算法建模，它主要包含三个环节，分别是文字角度识别、文字检测、文字识别三个部分。致谢 https://github.com/xiaofengShi/CHINESE-OCR, 本文源码可以从https://github.com/backyes/CHINESE-OCR 获取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备环境\n",
    "\n",
    "## 新建notebook，使用 hub.cn-east-p1.netease.com/staffai/notebook:tf-1.14.0-gpu-py3-ocr 创建Jupyter Notebook服务，参见交互式建模手册\n",
    "\n",
    "> 该镜像基于TensorFlow环境并安装了若干算法依赖， 无需额外操作\n",
    "\n",
    "    \n",
    "```bash\n",
    "apt-get install -y python-pydot python-pydot-ng graphviz cuda-cusparse-dev-10-0 cuda-cublas-dev-10-0  cmake vim cuda-curand-dev-10-0\n",
    "pip install pydot==1.4.1 graphviz==0.14.2\n",
    "pip install easydict -i https://pypi.tuna.tsinghua.edu.cn/simple/ ##选择国内源，速度更快\n",
    "pip install keras==2.0.8  -i https://pypi.tuna.tsinghua.edu.cn/simple/  \n",
    "pip install Cython opencv-python -i https://pypi.tuna.tsinghua.edu.cn/simple/ \n",
    "pip install matplotlib -i https://pypi.tuna.tsinghua.edu.cn/simple/ \n",
    "pip install -U pillow -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "pip install  h5py lmdb mahotas -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "pip install futures==3.1.1 -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "pip install torch==1.0.1  torchvision==0.2.0 \n",
    "pip install futures==3.1.1 -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "pip install tensorflow==1.13.1 tensorflow-gpu==1.13.1\n",
    "pip install warpctc-pytorch10-cuda90==0.1.3\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载 https://github.com/backyes/CHINESE-OCR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CHINESE-OCR'...\n",
      "remote: Enumerating objects: 42, done.\u001b[K\n",
      "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
      "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
      "^Cceiving objects:   9% (49/514), 972.01 KiB | 52.00 KiB/s   \n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/backyes/CHINESE-OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备基本环节环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /home/jovyan/CHINESE-OCR/ctpn/lib/utils/bbox.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /home/jovyan/CHINESE-OCR/ctpn/lib/utils/cython_nms.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /home/jovyan/CHINESE-OCR/ctpn/lib/utils/gpu_nms.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "\n",
      "Error compiling Cython file:\n",
      "------------------------------------------------------------\n",
      "...\n",
      "# --------------------------------------------------------\n",
      "\n",
      "import numpy as np\n",
      "cimport numpy as np\n",
      "\n",
      "cimport\n",
      "      ^\n",
      "------------------------------------------------------------\n",
      "\n",
      "gpu_nms.pyx:11:7: Expected an identifier\n",
      "running build_ext\n",
      "skipping 'bbox.c' Cython extension (up-to-date)\n",
      "skipping 'cython_nms.c' Cython extension (up-to-date)\n",
      "skipping 'gpu_nms.cpp' Cython extension (up-to-date)\n",
      "building 'utils.bbox' extension\n",
      "creating build\n",
      "creating build/temp.linux-x86_64-3.6\n",
      "{'gcc': ['-Wno-cpp', '-Wno-unused-function']}\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c bbox.c -o build/temp.linux-x86_64-3.6/bbox.o -Wno-cpp -Wno-unused-function\n",
      "creating /home/jovyan/CHINESE-OCR/ctpn/lib/utils/utils\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/bbox.o -o /home/jovyan/CHINESE-OCR/ctpn/lib/utils/utils/bbox.cpython-36m-x86_64-linux-gnu.so\n",
      "building 'utils.cython_nms' extension\n",
      "{'gcc': ['-Wno-cpp', '-Wno-unused-function']}\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c cython_nms.c -o build/temp.linux-x86_64-3.6/cython_nms.o -Wno-cpp -Wno-unused-function\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cython_nms.o -o /home/jovyan/CHINESE-OCR/ctpn/lib/utils/utils/cython_nms.cpython-36m-x86_64-linux-gnu.so\n",
      "building 'utils.gpu_nms' extension\n",
      "{'gcc': ['-Wno-unused-function'], 'nvcc': ['-arch=sm_35', '--ptxas-options=-v', '-c', '--compiler-options', \"'-fPIC'\"]}\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/local/cuda/include -I/usr/include/python3.6m -c nms_kernel.cu -o build/temp.linux-x86_64-3.6/nms_kernel.o -arch=sm_35 --ptxas-options=-v -c --compiler-options '-fPIC'\n",
      "ptxas info    : 0 bytes gmem\n",
      "ptxas info    : Compiling entry function '_Z10nms_kernelifPKfPy' for 'sm_35'\n",
      "ptxas info    : Function properties for _Z10nms_kernelifPKfPy\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 23 registers, 1280 bytes smem, 344 bytes cmem[0], 16 bytes cmem[2]\n",
      "{'gcc': ['-Wno-unused-function'], 'nvcc': ['-arch=sm_35', '--ptxas-options=-v', '-c', '--compiler-options', \"'-fPIC'\"]}\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/local/cuda/include -I/usr/include/python3.6m -c gpu_nms.cpp -o build/temp.linux-x86_64-3.6/gpu_nms.o -Wno-unused-function\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1832:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kgpu_nms.cpp:283\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
      " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
      "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/nms_kernel.o build/temp.linux-x86_64-3.6/gpu_nms.o -L/usr/local/cuda/lib64 -Wl,--enable-new-dtags,-R/usr/local/cuda/lib64 -lcudart -o /home/jovyan/CHINESE-OCR/ctpn/lib/utils/utils/gpu_nms.cpython-36m-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "!cd ./ctpn/lib/utils && sh make.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备数据\n",
    "\n",
    "从 链接: https://pan.baidu.com/s/1vWa604CEGJZNEpys0K9N7A 提取码: p3xy， 将下载的数据解压到代码工程根目录， 解压后目录如下：\n",
    "\n",
    "```bash\n",
    "/home/jovyan/HINESE-OCR\n",
    "total 540492\n",
    "-rw-r--r-- 1 jovyan users       3520 Dec 14 21:00 CHINESE_OCR.ipynb\n",
    "-rw-r--r-- 1 jovyan users       1052 Dec 14 20:58 Dockerfile\n",
    "-rw-r--r-- 1 jovyan users      11346 Dec  8 11:13 README.md\n",
    "-rw-r--r-- 1 jovyan users  553431812 Dec  9 15:39 VGG_imagenet.npy\n",
    "drwxr-xr-x 2 jovyan users       3611 Dec  9 18:37 __pycache__\n",
    "drwxr-xr-x 3 jovyan users       1878 Dec 14 10:24 angle\n",
    "drwxr-xr-x 2 jovyan users     121748 Dec  8 11:13 asset\n",
    "-rw-r--r-- 1 jovyan users        404 Dec 14 10:24 conf.py\n",
    "drwxr-xr-x 4 jovyan users      30309 Dec 14 10:24 crnn\n",
    "drwxr-xr-x 9 jovyan users  241743417 Dec 14 10:24 ctpn\n",
    "drwxr-xr-x 4 jovyan users 2940690554 Dec  9 20:48 datasets\n",
    "drwxr-xr-x 3 jovyan users      20490 Dec 14 10:24 ocr\n",
    "-rw-r--r-- 1 jovyan users       5160 Dec  9 13:12 pascal_voc.py\n",
    "drwxr-xr-x 6 jovyan users   56552660 Dec 14 10:24 predict\n",
    "-rwxr-xr-x 1 jovyan users        433 Dec 14 10:24 scripts.sh\n",
    "-rwxr-xr-x 1 jovyan users       3249 Dec 14 10:24 setup.sh\n",
    "drwxr-xr-x 8 jovyan users   11725974 Dec 14 10:24 train\n",
    "```\n",
    "\n",
    "其中\n",
    "\n",
    "```\n",
    "drwxr-xr-x 4 jovyan users 2940690554 Dec  9 20:48 datasets\n",
    "```\n",
    "datasets是准备的数据集以及一些预训练模型，下面分别介绍\n",
    "\n",
    "- VOCdevkit  用于训练检测模型的数据集\n",
    "\n",
    "- checkpoints detection模型预训练的模型checkpoints\n",
    "\n",
    "- modelAngle.h5 用于对文字方向进行推断的预训练模型\n",
    "\n",
    "- my_model_keras.h5 用于识别模型的预训练模型（Keras 模型）\n",
    "\n",
    "- netCRNN_pytorch.pth 用于识别的预训练模型（PyTorch模型），这个模型本demo里没有使用，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面查看配置文件，主要配置了数据集以及预训练模型的路径，如下:\n",
    "\n",
    "```bash\n",
    "tf-docker ~/CHINESE-OCR > cat  conf.py\n",
    "angel_model = '/home/jovyan/CHINESE-OCR/datasets/modelAngle.h5'\n",
    "# ctpn\n",
    "devkit_path = '/home/jovyan/CHINESE-OCR/datasets/VOCdevkit/'\n",
    "ctpn_pretrained_model = '/home/jovyan/CHINESE-OCR/datasets/VGG_imagenet.npy'\n",
    "ctpn_ckpt_path = '/home/jovyan/CHINESE-OCR/ctpn/output/ctpn_end2end/voc_2007_trainval'\n",
    "ctpn_ckpt_model = '/home/jovyan/CHINESE-OCR/ctpn/output/ctpn_end2end/voc_2007_trainval/VGGnet_fast_rcnn_iter_180000.ckpt'\n",
    "#crnn\n",
    "ocr_model = '/home/jovyan/CHINESE-OCR/datasets/my_model_keras.h5'\n",
    "netCRNN_pytorch_pth = '/home/jovyan/CHINESE-OCR/datasets/netCRNN_pytorch.pth'\n",
    "```\n",
    "\n",
    "请跟进实际datasets绝对路径修改此上面变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angel_model = '/home/jovyan/CHINESE-OCR/datasets/modelAngle.h5'\n",
      "# ctpn\n",
      "devkit_path = '/home/jovyan/CHINESE-OCR/datasets/VOCdevkit/'\n",
      "ctpn_pretrained_model = '/home/jovyan/CHINESE-OCR/datasets/VGG_imagenet.npy'\n",
      "ctpn_ckpt_path = '/home/jovyan/CHINESE-OCR/ctpn/output/ctpn_end2end/voc_2007_trainval'\n",
      "ctpn_ckpt_model = '/home/jovyan/CHINESE-OCR/ctpn/output/ctpn_end2end/voc_2007_trainval/VGGnet_fast_rcnn_iter_180000.ckpt'\n",
      "#crnn\n",
      "ocr_model = '/home/jovyan/CHINESE-OCR/datasets/my_model_keras.h5'\n",
      "netCRNN_pytorch_pth = '/home/jovyan/CHINESE-OCR/datasets/netCRNN_pytorch.pth'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat conf.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  训练模型\n",
    "\n",
    "##  训练检测模型\n",
    "\n",
    "下面主要介绍重新fine tuning 检测模型以及识别模型。 注意你需要一个内存足够匹配数据集的Jupyter Notebook否则可能无法加载数据。如果要使用算法平台分布式训练能力请参考其他文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jovyan/CHINESE-OCR/ctpn/lib/fast_rcnn/config.py:324: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n",
      "Using config:~~~~~~~~~~~~~~~~\n",
      "<bound method imdb.default_roidb of <ctpn.lib.datasets.pascal_voc.pascal_voc object at 0x7f5e2c138588>>\n",
      "Loaded dataset `voc_2007_trainval` for training\n",
      "Appending horizontally-flipped training examples...\n",
      "voc_2007_trainval gt roidb loaded from /home/jovyan/CHINESE-OCR/ctpn/data/cache/voc_2007_trainval_gt_roidb.pkl\n",
      "done\n",
      "Preparing training data...\n",
      "done\n",
      "Output will be saved to `/home/jovyan/CHINESE-OCR/ctpn/output/ctpn_end2end/voc_2007_trainval`\n",
      "Logs will be saved to `/home/jovyan/CHINESE-OCR/ctpn/logs/ctpn/voc_2007_trainval/2020-12-15-11-21-21`\n",
      "Tensor(\"data:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Tensor(\"conv5_3/conv5_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"rpn_conv/3x3/rpn_conv/3x3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/CHINESE-OCR/ctpn/lib/networks/network.py:101: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/jovyan/CHINESE-OCR/ctpn/lib/networks/network.py:105: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "Tensor(\"lstm_o/Reshape_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"lstm_o/Reshape_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"rpn_cls_score/Reshape_1:0\", shape=(?, ?, ?, 20), dtype=float32)\n",
      "Tensor(\"gt_boxes:0\", shape=(?, 5), dtype=float32)\n",
      "Tensor(\"gt_ishard:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"dontcare_areas:0\", shape=(?, 4), dtype=float32)\n",
      "Tensor(\"im_info:0\", shape=(?, 3), dtype=float32)\n",
      "WARNING:tensorflow:From /home/jovyan/CHINESE-OCR/ctpn/lib/networks/network.py:245: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "Tensor(\"rpn_cls_score/Reshape_1:0\", shape=(?, ?, ?, 20), dtype=float32)\n",
      "2020-12-15 11:21:24.393700: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-12-15 11:21:24.601369: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1840f40 executing computations on platform CUDA. Devices:\n",
      "2020-12-15 11:21:24.601461: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2020-12-15 11:21:24.604835: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200100000 Hz\n",
      "2020-12-15 11:21:24.607754: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x17d0bc0 executing computations on platform Host. Devices:\n",
      "2020-12-15 11:21:24.607807: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2020-12-15 11:21:24.608546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:82:00.0\n",
      "totalMemory: 10.92GiB freeMemory: 10.77GiB\n",
      "2020-12-15 11:21:24.608602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-12-15 11:21:24.614754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-12-15 11:21:24.614806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-12-15 11:21:24.614820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-12-15 11:21:24.614935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8383 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)\n",
      "Computing bounding-box regression targets...\n",
      "bbox target means:\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[0. 0. 0. 0.]\n",
      "bbox target stdevs:\n",
      "[[0.1 0.1 0.2 0.2]\n",
      " [0.1 0.1 0.2 0.2]]\n",
      "[0.1 0.1 0.2 0.2]\n",
      "Normalizing targets\n",
      "done\n",
      "Solving...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "output_dir: /home/jovyan/CHINESE-OCR/ctpn/output/ctpn_end2end/voc_2007_trainval\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "Restoring from /home/jovyan/CHINESE-OCR/ctpn/output/ctpn_end2end/voc_2007_trainval/VGGnet_fast_rcnn_iter_180000.ckpt... done\n",
      "180000 280000\n",
      "180000\n",
      "<tf.Variable 'Variable:0' shape=() dtype=float32_ref>\n",
      "2020-12-15 11:21:32.735204: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
      "iter: 180000 / 280000, total loss: 0.7366, model loss: 0.4420, rpn_loss_cls: 0.1334, rpn_loss_box: 0.3086, lr: 0.000100\n",
      "speed: 3.531s / iter\n",
      "180001\n",
      "180002\n",
      "180003\n",
      "180004\n",
      "180005\n",
      "180006\n",
      "180007\n",
      "180008\n",
      "180009\n",
      "180010\n",
      "iter: 180010 / 280000, total loss: 0.6357, model loss: 0.3412, rpn_loss_cls: 0.0654, rpn_loss_box: 0.2757, lr: 0.000100\n",
      "speed: 0.202s / iter\n",
      "180011\n",
      "180012\n",
      "180013\n",
      "180014\n",
      "180015\n",
      "180016\n",
      "180017\n",
      "180018\n",
      "180019\n",
      "180020\n",
      "iter: 180020 / 280000, total loss: 0.5943, model loss: 0.2997, rpn_loss_cls: 0.0341, rpn_loss_box: 0.2655, lr: 0.000100\n",
      "speed: 1.309s / iter\n",
      "180021\n",
      "180022\n",
      "180023\n",
      "180024\n",
      "180025\n",
      "180026\n",
      "180027\n",
      "180028\n",
      "180029\n",
      "180030\n",
      "iter: 180030 / 280000, total loss: 0.3772, model loss: 0.0826, rpn_loss_cls: 0.0453, rpn_loss_box: 0.0374, lr: 0.000100\n",
      "speed: 1.132s / iter\n",
      "180031\n",
      "180032\n",
      "180033\n",
      "180034\n",
      "180035\n",
      "180036\n",
      "180037\n",
      "180038\n",
      "180039\n",
      "180040\n",
      "iter: 180040 / 280000, total loss: 0.6823, model loss: 0.3877, rpn_loss_cls: 0.0214, rpn_loss_box: 0.3664, lr: 0.000100\n",
      "speed: 0.200s / iter\n",
      "180041\n",
      "180042\n",
      "180043\n",
      "180044\n",
      "180045\n",
      "180046\n",
      "180047\n",
      "180048\n",
      "180049\n",
      "180050\n",
      "iter: 180050 / 280000, total loss: 0.5916, model loss: 0.2970, rpn_loss_cls: 0.0381, rpn_loss_box: 0.2588, lr: 0.000100\n",
      "speed: 0.196s / iter\n",
      "180051\n",
      "180052\n",
      "180053\n",
      "180054\n",
      "180055\n",
      "180056\n",
      "180057\n",
      "180058\n",
      "180059\n",
      "180060\n",
      "iter: 180060 / 280000, total loss: 0.3847, model loss: 0.0901, rpn_loss_cls: 0.0056, rpn_loss_box: 0.0845, lr: 0.000100\n",
      "speed: 0.192s / iter\n",
      "180061\n",
      "180062\n",
      "180063\n",
      "180064\n",
      "180065\n",
      "180066\n",
      "180067\n",
      "180068\n",
      "180069\n",
      "180070\n",
      "iter: 180070 / 280000, total loss: 0.4932, model loss: 0.1986, rpn_loss_cls: 0.0543, rpn_loss_box: 0.1443, lr: 0.000100\n",
      "speed: 0.247s / iter\n",
      "180071\n",
      "180072\n",
      "180073\n",
      "180074\n",
      "180075\n",
      "180076\n",
      "180077\n",
      "180078\n",
      "180079\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# transfer learning detection model\n",
    "!PYTHONPATH=./ python ctpn/ctpn/train_net.py # 重新基于/home/jovyan/CHINESE-OCR/datasets/VOCdevkit/ 数据集微调模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试检测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "2020-12-15 11:52:21.339924: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-12-15 11:52:21.545014: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x13cae50 executing computations on platform CUDA. Devices:\n",
      "2020-12-15 11:52:21.545083: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2020-12-15 11:52:21.548322: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200100000 Hz\n",
      "2020-12-15 11:52:21.551225: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1a8f580 executing computations on platform Host. Devices:\n",
      "2020-12-15 11:52:21.551256: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2020-12-15 11:52:21.551482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:82:00.0\n",
      "totalMemory: 10.92GiB freeMemory: 10.77GiB\n",
      "2020-12-15 11:52:21.551530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-12-15 11:52:21.558168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-12-15 11:52:21.558198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-12-15 11:52:21.558214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-12-15 11:52:21.558341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10481 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)\n",
      "Tensor(\"Placeholder:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Tensor(\"conv5_3/conv5_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"rpn_conv/3x3/rpn_conv/3x3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/CHINESE-OCR/ctpn/lib/networks/network.py:101: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/jovyan/CHINESE-OCR/ctpn/lib/networks/network.py:105: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "Tensor(\"lstm_o/Reshape_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"lstm_o/Reshape_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"rpn_cls_score/Reshape_1:0\", shape=(?, ?, ?, 20), dtype=float32)\n",
      "Tensor(\"rpn_cls_prob:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "Tensor(\"Reshape_2:0\", shape=(?, ?, ?, 20), dtype=float32)\n",
      "Tensor(\"rpn_bbox_pred/Reshape_1:0\", shape=(?, ?, ?, 40), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 3), dtype=float32)\n",
      "WARNING:tensorflow:From /home/jovyan/CHINESE-OCR/ctpn/lib/networks/network.py:223: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "Loading network VGGnet_test... \n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# 用demo测试这个检测模型\n",
    "!PYTHONPATH=./ python ctpn/ctpn/demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "展示测试结果\n",
    "\n",
    "\n",
    "![test](ctpn/data/results/009.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练识别模型\n",
    "\n",
    "1. 数据集准备过程可以参见 train/keras_train/create_dataset，这里不赘述。\n",
    "\n",
    "2. 主要利用keras + TensorFlow 构建的crnn识别模型，基于/home/jovyan/CHINESE-OCR/datasets/my_model_keras.h5 模型进行transfer learning训练， 训练输出的模型在 `/home/jovyan/CHINESE-OCR/train/keras_train/output`, 详细训练参数可以参见 `train/keras_train/trainbatch.py` 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n",
      "base_path /home/jovyan/CHINESE-OCR/train/keras_train\n",
      "Creating save model path!!\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1154: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3654: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3634: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "the_input (InputLayer)           (None, 32, None, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 32, None, 64)  640         the_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)             (None, 16, None, 64)  0           conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                   (None, 16, None, 128) 73856       pool1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)             (None, 8, None, 128)  0           conv2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                   (None, 8, None, 256)  295168      pool2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                   (None, 8, None, 256)  590080      conv3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D) (None, 8, None, 256)  0           conv4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)             (None, 4, None, 256)  0           zero_padding2d_1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                   (None, 4, None, 512)  1180160     pool3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 4, None, 512)  16          conv5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                   (None, 4, None, 512)  2359808     batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 4, None, 512)  16          conv6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D) (None, 4, None, 512)  0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "pool4 (MaxPooling2D)             (None, 2, None, 512)  0           zero_padding2d_2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                   (None, 1, None, 512)  1049088     pool4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "permute (Permute)                (None, None, 1, 512)  0           conv7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "timedistrib (TimeDistributed)    (None, None, 512)     0           permute[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "blstm1 (Bidirectional)           (None, None, 512)     1181184     timedistrib[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "blstm1_out (Dense)               (None, None, 256)     131328      blstm1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "blstm2 (Bidirectional)           (None, None, 512)     787968      blstm1_out[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "blstm2_out (Dense)               (None, None, 5531)    2837403     blstm2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "the_labels (InputLayer)          (None, None)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_length (InputLayer)        (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "label_length (InputLayer)        (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "ctc (Lambda)                     (None, 1)             0           blstm2_out[0][0]                 \n",
      "                                                                   the_labels[0][0]                 \n",
      "                                                                   input_length[0][0]               \n",
      "                                                                   label_length[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 10,486,715\n",
      "Trainable params: 10,486,699\n",
      "Non-trainable params: 16\n",
      "____________________________________________________________________________________________________\n",
      "2020-12-15 11:57:13.437595: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-12-15 11:57:13.648381: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x35fcf10 executing computations on platform CUDA. Devices:\n",
      "2020-12-15 11:57:13.648460: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2020-12-15 11:57:13.652455: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200100000 Hz\n",
      "2020-12-15 11:57:13.655917: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3909450 executing computations on platform Host. Devices:\n",
      "2020-12-15 11:57:13.655976: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2020-12-15 11:57:13.658062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:82:00.0\n",
      "totalMemory: 10.92GiB freeMemory: 10.77GiB\n",
      "2020-12-15 11:57:13.658126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-12-15 11:57:13.659405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-12-15 11:57:13.659437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-12-15 11:57:13.659451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-12-15 11:57:13.659581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3353 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)\n",
      "nSamples:8\n",
      "nSamples:72\n",
      "Start training!!\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "2020-12-15 11:57:25.649320: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
      "8/8 [==============================] - 0s\n",
      "16/16 [==============================] - 0s\n",
      "Learning rate is:  0.01\n",
      "Time: [2020/12/15-11:57:31]--Step/Epoch/Total: [0/0/1000000]\n",
      "\tTraining Loss is: [0.043752171099185944]\n",
      "\tVal Loss is: [0.6159176826477051]\n",
      "\tSpeed is: [3.784724450522023] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /home/jovyan/CHINESE-OCR/train/keras_train/output//my_model_keras.h5\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "8/8 [==============================] - 0s\n",
      "16/16 [==============================] - 0s\n",
      "Learning rate is:  0.01\n",
      "Time: [2020/12/15-11:58:14]--Step/Epoch/Total: [50/50/1000000]\n",
      "\tTraining Loss is: [0.004348286893218756]\n",
      "\tVal Loss is: [1.0609650611877441]\n",
      "\tSpeed is: [133.01029248727076] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /home/jovyan/CHINESE-OCR/train/keras_train/output//my_model_keras.h5\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "8/8 [==============================] - 0s\n",
      "16/16 [==============================] - 0s\n",
      "Learning rate is:  0.01\n",
      "Time: [2020/12/15-11:58:59]--Step/Epoch/Total: [100/100/1000000]\n",
      "\tTraining Loss is: [0.003855297574773431]\n",
      "\tVal Loss is: [2.7304635047912598]\n",
      "\tSpeed is: [128.5820882253218] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /home/jovyan/CHINESE-OCR/train/keras_train/output//my_model_keras.h5\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "8/8 [==============================] - 0s\n",
      "16/16 [==============================] - 0s\n",
      "Learning rate is:  0.01\n",
      "Time: [2020/12/15-11:59:45]--Step/Epoch/Total: [150/150/1000000]\n",
      "\tTraining Loss is: [0.0037169053684920073]\n",
      "\tVal Loss is: [1.1042464971542358]\n",
      "\tSpeed is: [129.18795515895064] Samples/Secs\n",
      "\tWriting to the file: log.txt\n",
      "\tSave model to disk: /home/jovyan/CHINESE-OCR/train/keras_train/output//my_model_keras.h5\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "IMG_SHAPE: (8, 32, 256, 1)\n",
      "LABEL_SHAPE: (8, 10)\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train/keras_train/trainbatch.py\", line 107, in <module>\n",
      "    for X, Y in train_loader:\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 626, in __next__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 124, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 50, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH=./ python train/keras_train/trainbatch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  端到端的测试模型\n",
    "\n",
    "主要利用训练出的模型进行最终的测试评估工作。\n",
    "\n",
    "测试数据位于 `/home/jovyan/CHINESE-OCR/predict/test`, `predict/demo.py` 文件会对测试数据进行逐个测试，并输出识别结果。 相对模型微调请实际分析相关底层代码，此处不赘述细节，仅做demo。\n",
    "\n",
    "```python\n",
    "tf-docker ~/CHINESE-OCR/predict > cat demo.py\n",
    "# coding:utf-8\n",
    "\n",
    "import os\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from predict import model\n",
    "\n",
    "paths = glob(os.path.dirname(__file__) + '/test/*.*')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    im = Image.open(os.path.dirname(__file__) + \"/test/test_pre.png\")\n",
    "    img = np.array(im.convert('RGB'))\n",
    "    t = time.time()\n",
    "    '''\n",
    "    result,img,angel分别对应-识别结果，图像的数组，文字旋转角度\n",
    "    '''\n",
    "    result, img, angle = model.model(\n",
    "        img, model='keras', adjust=True, detectAngle=True)\n",
    "    print(\"It takes time:{}s\".format(time.time() - t))\n",
    "    print(\"---------------------------------------\")\n",
    "    for key in result:\n",
    "        print(result[key][1])\n",
    "\n",
    "    im = Image.open(os.path.dirname(__file__) + \"/test/img/result.png\")\n",
    "    img = np.array(im.convert('RGB'))\n",
    "    t = time.time()\n",
    "    '''\n",
    "    result,img,angel分别对应-识别结果，图像的数组，文字旋转角度\n",
    "    '''\n",
    "    result, img, angle = model.model(\n",
    "        img, model='keras', adjust=True, detectAngle=True)\n",
    "    print(\"It takes time:{}s\".format(time.time() - t))\n",
    "    print(\"---------------------------------------\")\n",
    "    for key in result:\n",
    "        print(result[key][1])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict/test/001.jpg\t\t\t\t predict/test/IMG_0689.JPG\n",
      "predict/test/002.jpg\t\t\t\t predict/test/IMG_1563.JPG\n",
      "predict/test/003.jpg\t\t\t\t predict/test/WechatIMG305.jpeg\n",
      "predict/test/004.jpg\t\t\t\t predict/test/ctpn____.png\n",
      "predict/test/005.jpg\t\t\t\t predict/test/demo-card-1.jpeg\n",
      "predict/test/006.jpg\t\t\t\t predict/test/qqqqqq.png\n",
      "predict/test/007.jpg\t\t\t\t predict/test/test.jpeg\n",
      "predict/test/008.jpg\t\t\t\t predict/test/test.png\n",
      "predict/test/009.jpg\t\t\t\t predict/test/test1.png\n",
      "predict/test/010.png\t\t\t\t predict/test/test2.png\n",
      "predict/test/1.png\t\t\t\t predict/test/test_ctpn.png\n",
      "predict/test/2.png\t\t\t\t predict/test/test_pre.png\n",
      "predict/test/3.png\t\t\t\t predict/test/test_result.png\n",
      "predict/test/4.jpg\t\t\t\t predict/test/ttttt.png\n",
      "predict/test/CgQgIll5TaGADkiiAAFhxGXefcA951.jpg  predict/test/ttttt_result.png\n",
      "predict/test/CgQgIlljJlyAF3fGAABk3TG5RM4164.jpg\n",
      "\n",
      "predict/test/img:\n",
      "result.png  tmp.jpg  tmp.png  tmp1.jpg\ttmp1.png\n"
     ]
    }
   ],
   "source": [
    "!ls predict/test/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试2个图片： \n",
    "\n",
    "- predict/test/test_pre.png\n",
    "\n",
    "![test](predict//test/test_pre.png)\n",
    "\n",
    "- predict/test/img/result.png\n",
    "\n",
    "![test](predict/test/img/result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n",
      "Tensor(\"Placeholder:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Tensor(\"conv5_3/conv5_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"rpn_conv/3x3/rpn_conv/3x3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "WARNING:tensorflow:From /home/jovyan/CHINESE-OCR/ctpn/lib/networks/network.py:101: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/jovyan/CHINESE-OCR/ctpn/lib/networks/network.py:105: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "Tensor(\"lstm_o/Reshape_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"lstm_o/Reshape_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"rpn_cls_score/Reshape_1:0\", shape=(?, ?, ?, 20), dtype=float32)\n",
      "Tensor(\"rpn_cls_prob:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "Tensor(\"Reshape_2:0\", shape=(?, ?, ?, 20), dtype=float32)\n",
      "Tensor(\"rpn_bbox_pred/Reshape_1:0\", shape=(?, ?, ?, 40), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 3), dtype=float32)\n",
      "WARNING:tensorflow:From /home/jovyan/CHINESE-OCR/ctpn/lib/networks/network.py:223: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "2020-12-15 12:39:54.595630: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-12-15 12:39:54.808383: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2f73a50 executing computations on platform CUDA. Devices:\n",
      "2020-12-15 12:39:54.808446: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2020-12-15 12:39:54.811772: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200100000 Hz\n",
      "2020-12-15 12:39:54.814615: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2f74680 executing computations on platform Host. Devices:\n",
      "2020-12-15 12:39:54.814649: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2020-12-15 12:39:54.814892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:82:00.0\n",
      "totalMemory: 10.92GiB freeMemory: 10.77GiB\n",
      "2020-12-15 12:39:54.814981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-12-15 12:39:54.822482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-12-15 12:39:54.822516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-12-15 12:39:54.822538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-12-15 12:39:54.822677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10481 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)\n",
      "Tensor_name is :  rpn_conv/3x3/biases\n",
      "Tensor_name is :  rpn_cls_score/weights\n",
      "Tensor_name is :  rpn_bbox_pred/biases\n",
      "Tensor_name is :  lstm_o/weights\n",
      "Tensor_name is :  lstm_o/bidirectional_rnn/fw/lstm_cell/bias\n",
      "Tensor_name is :  lstm_o/bidirectional_rnn/bw/lstm_cell/kernel\n",
      "Tensor_name is :  lstm_o/bidirectional_rnn/bw/lstm_cell/bias\n",
      "Tensor_name is :  conv5_3/weights\n",
      "Tensor_name is :  conv5_3/biases\n",
      "Tensor_name is :  lstm_o/biases\n",
      "Tensor_name is :  conv5_2/weights\n",
      "Tensor_name is :  conv2_2/weights\n",
      "Tensor_name is :  conv1_1/weights\n",
      "Tensor_name is :  conv4_2/weights\n",
      "Tensor_name is :  conv2_2/biases\n",
      "Tensor_name is :  conv2_1/biases\n",
      "Tensor_name is :  conv1_2/weights\n",
      "Tensor_name is :  conv4_1/biases\n",
      "Tensor_name is :  conv2_1/weights\n",
      "Tensor_name is :  rpn_cls_score/biases\n",
      "Tensor_name is :  conv1_2/biases\n",
      "Tensor_name is :  rpn_conv/3x3/weights\n",
      "Tensor_name is :  conv3_1/weights\n",
      "Tensor_name is :  conv4_3/weights\n",
      "Tensor_name is :  conv3_2/biases\n",
      "Tensor_name is :  rpn_bbox_pred/weights\n",
      "Tensor_name is :  conv3_2/weights\n",
      "Tensor_name is :  lstm_o/bidirectional_rnn/fw/lstm_cell/kernel\n",
      "Tensor_name is :  conv3_3/biases\n",
      "Tensor_name is :  conv5_2/biases\n",
      "Tensor_name is :  conv5_1/weights\n",
      "Tensor_name is :  conv3_3/weights\n",
      "Tensor_name is :  conv4_1/weights\n",
      "Tensor_name is :  conv1_1/biases\n",
      "Tensor_name is :  conv4_2/biases\n",
      "Tensor_name is :  conv3_1/biases\n",
      "Tensor_name is :  conv4_3/biases\n",
      "Tensor_name is :  conv5_1/biases\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "load vggnet done\n",
      "['/home/jovyan/CHINESE-OCR/ctpn/lib', '/home/jovyan/CHINESE-OCR/predict', '/home/jovyan/CHINESE-OCR', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1154: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3654: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3634: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "2020-12-15 12:39:59.015744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-12-15 12:39:59.015847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-12-15 12:39:59.015865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-12-15 12:39:59.015877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-12-15 12:39:59.016030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10481 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)\n",
      "2020-12-15 12:40:02.021341: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
      "The angel of this character is: 0\n",
      "Rotate the array of this img!\n",
      "It takes time:15.106428623199463s\n",
      "---------------------------------------\n",
      "，月1987年股市崩盎可能是现代从众效应引起的第一场危机。金融业普及了动J\n",
      "旧态投资组合傈险方法一\n",
      "法-一涉及傈护投资者避免投资组合亏损的方法。许多机构提」\n",
      "傍这种安全的交易方式:在市场向下时，卖空市场;在市场走高时，做多市场:\n",
      "月当然，上述方法只有市场一小部公人采园鄙力在之有效a\n",
      "，但是如果策略追随者变得很多，挤满整个市场空间，市场就会变得不稳定。J\n",
      ":月帝颈存，不房耐,很多人就会平仓，使得市价越来越低，在肉就全丑起题盎4\n",
      "月987年，有许多的跟风者，市场空间捌挤不堪，很多公枕模型述没有充公老廖」\n",
      "区盎巫更到\n",
      "，「事隔11年之后的1998年,另一场大危机随即而至，将俄罗斯市场卷人其中:\n",
      "月导致著名对冲基金 \n",
      "盎-丕美国长期资本管理公司倒闭。在1994年，美国长捌资本」\n",
      "傈督理公司是最大的对汴基金之一。它的经理把从所影门兄弟那里拳到的技术军受」\n",
      "科定量分析运用到极致。彼时，他们是新的金融市场主宰，人人都想从其惊人业]\n",
      "[额中分一称捌]\n",
      "「很陂,真他机稍 包括高盛、廖根土丹利、蛋晏兄弟及许多兹贿注基金韵」\n",
      "二-每一科郡鄙及在杆伺]\n",
      "，晏雷交易部门)开始娇解长期资本管理公司的投资策蹿 一每\n",
      "「众人蹿拥进人利润丰厚的相对价值债券套利投资领域。量化策略的眼风者充斥了\n",
      "这不布颈空间。风险模型不再那么精瘸，因为它不能反腴这种丛公现驽及甚潜在」\n",
      "彤彤。高杠杆准起的买守意味着一有风吹章动，就会在短时间内摧毁一家公司。]\n",
      "月1998年7月，大型投资机构所罗门兄弟公司开始对以往的跟风头寸进行渡」\n",
      ":仓。1998年8月，俄罗斯政府出现债拳违绚。当捌对公值基金盎路逃金之虫4\n",
      ":尸瘸“天觅震”之采。长瘸资军督理公司资临破产;许多人害伺这会破环整]\n",
      "「金盈系统,就妇20)年雷晏兄弟公司那样。美腴愉介人,私玉韵遇鲶炎方案4\n",
      "[力图遏捌混乱面引\n",
      "，「2000军,网驽腴韵帝盈翠高至竞谬之夜,狡资者蹿瘸，泡沫剧增。到2000]\n",
      "The angel of this character is: 0\n",
      "Rotate the array of this img!\n",
      "It takes time:5.653041839599609s\n",
      "---------------------------------------\n",
      "，产品名称:个体营养分析仪-型号:即03-Bp1u8\n",
      ":220v频率:50日2输入功率:95N\n",
      "，,输入电源:\n",
      "安全类别:I类BF型\n",
      "产产品注册编号:昏械注准20152210006\n",
      "出厂编号:7021602001B\n",
      "生产日期:2016年02月25日\n",
      "委托方/注册人:山西四海华辰科技有限公司\n",
      "住所:太原高新区产业路48号新岛科技园C座208室\n",
      "联系方式:0351-7037508\n",
      "，村科技园区大兴生物\n",
      ":医药产业基地天华大街33号院1号楼\n",
      ":生产许可证编号:京食药监械生产许可20140021号\n",
      "其他内容详见说明书\n"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH=./ python predict/demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
